{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Melbourne', 'NP', 'B-LOC'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('Australia', 'NP', 'B-LOC'),\n",
       " (')', 'Fpt', 'O'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('25', 'Z', 'O'),\n",
       " ('may', 'NC', 'O'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('EFE', 'NC', 'B-ORG'),\n",
       " (')', 'Fpt', 'O'),\n",
       " ('.', 'Fp', 'O')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word2features(sent,i):\n",
    "    word=sent[i][0]\n",
    "    postag=sent[i][1]\n",
    "    features=[\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i>0:\n",
    "        word1=sent[i-1][0]\n",
    "        postag1=sent[i-1][1]\n",
    "        features=([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "    \n",
    "    if i<len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "    return features\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jason 197609 409K Mar 10 19:09 ./conll2002-esp.crfsuite\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./conll2002-esp.crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_features': 7183,\n",
       " 'error_norm': 367.154101,\n",
       " 'feature_norm': 107.05366,\n",
       " 'linesearch_step': 1.0,\n",
       " 'linesearch_trials': 1,\n",
       " 'loss': 47845.715863,\n",
       " 'num': 50,\n",
       " 'scores': {},\n",
       " 'time': 0.234}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logparser.last_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,\n",
       " {'active_features': 7183,\n",
       "  'error_norm': 367.154101,\n",
       "  'feature_norm': 107.05366,\n",
       "  'linesearch_step': 1.0,\n",
       "  'linesearch_trials': 1,\n",
       "  'loss': 47845.715863,\n",
       "  'num': 50,\n",
       "  'scores': {},\n",
       "  'time': 0.234})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainer.logparser.iterations), trainer.logparser.iterations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x2e1f6afe7f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Coru√±a , 23 may ( EFECOM ) .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_sents[0]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: B-LOC I-LOC O O O O B-ORG O O\n",
      "Correct:   B-LOC I-LOC O O O O B-ORG O O\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 399 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       0.72      0.32      0.45      1084\n",
      "      I-LOC       0.61      0.53      0.57       325\n",
      "     B-MISC       0.61      0.18      0.28       339\n",
      "     I-MISC       0.68      0.40      0.50       557\n",
      "      B-ORG       0.72      0.41      0.52      1400\n",
      "      I-ORG       0.77      0.71      0.74      1104\n",
      "      B-PER       0.85      0.67      0.75       735\n",
      "      I-PER       0.81      0.84      0.83       634\n",
      "\n",
      "avg / total       0.74      0.52      0.59      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BaseTrainer',\n",
       " 'CRFSUITE_VERSION',\n",
       " 'CRFSuiteError',\n",
       " 'ItemSequence',\n",
       " 'Tagger',\n",
       " 'Trainer',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_dumpparser',\n",
       " '_logparser',\n",
       " '_pycrfsuite',\n",
       " 'absolute_import',\n",
       " 'contextlib',\n",
       " 'os',\n",
       " 'sys',\n",
       " 'tempfile']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pycrfsuite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Trainer in module pycrfsuite._pycrfsuite:\n",
      "\n",
      "class Trainer(BaseTrainer)\n",
      " |  The trainer class.\n",
      " |  \n",
      " |  This class maintains a data set for training, and provides an interface\n",
      " |  to various training algorithms.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  algorithm : {'lbfgs', 'l2sgd', 'ap', 'pa', 'arow'}\n",
      " |      The name of the training algorithm. See :meth:`Trainer.select`.\n",
      " |  \n",
      " |  params : dict, optional\n",
      " |      Training parameters. See :meth:`Trainer.set_params`\n",
      " |      and :meth:`Trainer.set`.\n",
      " |  \n",
      " |  verbose : boolean\n",
      " |      Whether to print debug messages during training. Default is True.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Trainer\n",
      " |      BaseTrainer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  message(self, message)\n",
      " |      Trainer.message(self, message)\n",
      " |  \n",
      " |  on_end(self, log)\n",
      " |      Trainer.on_end(self, log)\n",
      " |  \n",
      " |  on_featgen_end(self, log)\n",
      " |      Trainer.on_featgen_end(self, log)\n",
      " |  \n",
      " |  on_featgen_progress(self, log, percent)\n",
      " |      Trainer.on_featgen_progress(self, log, percent)\n",
      " |  \n",
      " |  on_iteration(self, log, info)\n",
      " |      Trainer.on_iteration(self, log, info)\n",
      " |  \n",
      " |  on_optimization_end(self, log)\n",
      " |      Trainer.on_optimization_end(self, log)\n",
      " |  \n",
      " |  on_prepare_error(self, log)\n",
      " |      Trainer.on_prepare_error(self, log)\n",
      " |  \n",
      " |  on_prepared(self, log)\n",
      " |      Trainer.on_prepared(self, log)\n",
      " |  \n",
      " |  on_start(self, log)\n",
      " |      Trainer.on_start(self, log)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  logparser = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseTrainer:\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  append(...)\n",
      " |      BaseTrainer.append(self, xseq, yseq, int group=0)\n",
      " |      \n",
      " |      Append an instance (item/label sequence) to the data set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      xseq : a sequence of item features\n",
      " |          The item sequence of the instance. ``xseq`` should be a list\n",
      " |          of item features or an :class:`~ItemSequence` instance.\n",
      " |          Allowed item features formats are the same as described\n",
      " |          in :class:`~ItemSequence` docs.\n",
      " |      \n",
      " |      yseq : a sequence of strings\n",
      " |          The label sequence of the instance. The number\n",
      " |          of elements in yseq must be identical to that\n",
      " |          in xseq.\n",
      " |      \n",
      " |      group : int, optional\n",
      " |          The group number of the instance. Group numbers are used to\n",
      " |          select subset of data for heldout evaluation.\n",
      " |  \n",
      " |  clear(...)\n",
      " |      BaseTrainer.clear(self)\n",
      " |      Remove all instances in the data set.\n",
      " |  \n",
      " |  get(...)\n",
      " |      BaseTrainer.get(self, name)\n",
      " |      \n",
      " |      Get the value of a training parameter.\n",
      " |      This function gets a parameter value for the graphical model and\n",
      " |      training algorithm specified by :meth:`Trainer.select` method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          The parameter name.\n",
      " |  \n",
      " |  get_params(...)\n",
      " |      BaseTrainer.get_params(self)\n",
      " |      \n",
      " |      Get training parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict\n",
      " |          A dictionary with ``{parameter_name: parameter_value}``\n",
      " |          with all trainer parameters.\n",
      " |  \n",
      " |  help(...)\n",
      " |      BaseTrainer.help(self, name)\n",
      " |      \n",
      " |      Get the description of a training parameter.\n",
      " |      This function obtains the help message for the parameter specified\n",
      " |      by the name. The graphical model and training algorithm must be\n",
      " |      selected by :meth:`Trainer.select` method before calling this method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          The parameter name.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      string\n",
      " |          The description (help message) of the parameter.\n",
      " |  \n",
      " |  params(...)\n",
      " |      BaseTrainer.params(self)\n",
      " |      \n",
      " |      Obtain the list of parameters.\n",
      " |      \n",
      " |      This function returns the list of parameter names available for the\n",
      " |      graphical model and training algorithm specified in Trainer constructor\n",
      " |      or by :meth:`Trainer.select` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of strings\n",
      " |          The list of parameters available for the current\n",
      " |          graphical model and training algorithm.\n",
      " |  \n",
      " |  select(...)\n",
      " |      BaseTrainer.select(self, algorithm, type='crf1d')\n",
      " |      \n",
      " |      Initialize the training algorithm.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      algorithm : {'lbfgs', 'l2sgd', 'ap', 'pa', 'arow'}\n",
      " |          The name of the training algorithm.\n",
      " |      \n",
      " |          * 'lbfgs' for Gradient descent using the L-BFGS method,\n",
      " |          * 'l2sgd' for Stochastic Gradient Descent with L2 regularization term\n",
      " |          * 'ap' for Averaged Perceptron\n",
      " |          * 'pa' for Passive Aggressive\n",
      " |          * 'arow' for Adaptive Regularization Of Weight Vector\n",
      " |      \n",
      " |      type : string, optional\n",
      " |          The name of the graphical model.\n",
      " |  \n",
      " |  set(...)\n",
      " |      BaseTrainer.set(self, name, value)\n",
      " |      \n",
      " |      Set a training parameter.\n",
      " |      This function sets a parameter value for the graphical model and\n",
      " |      training algorithm specified by :meth:`Trainer.select` method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          The parameter name.\n",
      " |      value : string\n",
      " |          The value of the parameter.\n",
      " |  \n",
      " |  set_params(...)\n",
      " |      BaseTrainer.set_params(self, params)\n",
      " |      \n",
      " |      Set training parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : dict\n",
      " |          A dict with parameters ``{name: value}``\n",
      " |  \n",
      " |  train(...)\n",
      " |      BaseTrainer.train(self, model, int holdout=-1)\n",
      " |      \n",
      " |      Run the training algorithm.\n",
      " |      This function starts the training algorithm with the data set given\n",
      " |      by :meth:`Trainer.append` method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      model : string\n",
      " |          The filename to which the trained model is stored.\n",
      " |          If this value is empty, this function does not\n",
      " |          write out a model file.\n",
      " |      \n",
      " |      holdout : int, optional\n",
      " |          The group number of holdout evaluation. The\n",
      " |          instances with this group number will not be used\n",
      " |          for training, but for holdout evaluation.\n",
      " |          Default value is -1, meaning \"use all instances for training\".\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseTrainer:\n",
      " |  \n",
      " |  verbose\n",
      " |      verbose: object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BaseTrainer:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pycrfsuite.Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
